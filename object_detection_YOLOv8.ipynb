{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a38fda4-ef13-4a8c-8a92-df4f2287f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from supervision.draw.color import ColorPalette\n",
    "# from supervision.tools.detections import Detections, BoxAnnotator\n",
    "\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5aeab0-868b-456a-96cc-716e6b35c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d95542b0-b155-4f9c-9edb-2ed5f3d7882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8m summary (fused): 218 layers, 25886080 parameters, 0 gradients, 78.9 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb29837-4615-4819-a3df-6ed7d7582248",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES_DICT = model.model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0265dad6-308f-4e8d-abd5-1e3d5e5889f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator(color=ColorPalette.default(), thickness=3, text_thickness=3, text_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08661aac-7b29-4835-b92f-b9d21caaabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bboxes(results, frame):\n",
    "\n",
    "    xyxys = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # Extract detections for person class\n",
    "    for result in results[0]:\n",
    "        class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "        if class_id == 0:\n",
    "            xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "            confidences.append(result.boxes.conf.cpu().numpy())\n",
    "            class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "\n",
    "    # Setup detections for visualization\n",
    "    detections = sv.Detections(\n",
    "        xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "        confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "        class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "    )\n",
    "\n",
    "    # Format custom labels\n",
    "    labels = [f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "                    for _, mask, confidence, class_id, tracker_id\n",
    "                    in detections]\n",
    "\n",
    "    # Annotate and display frame\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14eabec-87cb-43b4-a52e-99a78462711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(frame):\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37c0747c-136f-4552-ae8c-abee5097b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "\n",
    "    model = YOLO(\"yolov8m.pt\")  # load a pretrained YOLOv8n model\n",
    "    model.fuse()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "683d495f-2934-41c3-b7df-f2acf9e8c89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 32.0ms\n",
      "Speed: 0.0ms preprocess, 32.0ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 488.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.9ms\n",
      "Speed: 0.0ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.8ms\n",
      "Speed: 0.0ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 0.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.5ms\n",
      "Speed: 0.0ms preprocess, 25.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 21.6ms\n",
      "Speed: 0.0ms preprocess, 21.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.0ms\n",
      "Speed: 0.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.3ms\n",
      "Speed: 0.0ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.2ms\n",
      "Speed: 0.0ms preprocess, 15.2ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.8ms\n",
      "Speed: 0.0ms preprocess, 24.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.2ms\n",
      "Speed: 0.0ms preprocess, 28.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 38.9ms\n",
      "Speed: 0.0ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 32.5ms\n",
      "Speed: 6.5ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 33.1ms\n",
      "Speed: 0.0ms preprocess, 33.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.3ms\n",
      "Speed: 3.5ms preprocess, 30.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 32.7ms\n",
      "Speed: 0.0ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.7ms\n",
      "Speed: 3.7ms preprocess, 30.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.1ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 32.9ms\n",
      "Speed: 0.0ms preprocess, 32.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.5ms\n",
      "Speed: 0.0ms preprocess, 32.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 36.9ms\n",
      "Speed: 6.0ms preprocess, 36.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 29.6ms\n",
      "Speed: 3.5ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 31.6ms\n",
      "Speed: 0.0ms preprocess, 31.6ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.7ms\n",
      "Speed: 0.0ms preprocess, 32.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 28.4ms\n",
      "Speed: 3.6ms preprocess, 28.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 34.8ms\n",
      "Speed: 1.2ms preprocess, 34.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 31.4ms\n",
      "Speed: 2.5ms preprocess, 31.4ms inference, 6.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 28.6ms\n",
      "Speed: 2.5ms preprocess, 28.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 33.0ms\n",
      "Speed: 0.0ms preprocess, 33.0ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 37.4ms\n",
      "Speed: 0.0ms preprocess, 37.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 29.5ms\n",
      "Speed: 2.6ms preprocess, 29.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 32.6ms\n",
      "Speed: 0.0ms preprocess, 32.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 35.6ms\n",
      "Speed: 5.1ms preprocess, 35.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 40.9ms\n",
      "Speed: 0.0ms preprocess, 40.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 41.2ms\n",
      "Speed: 0.0ms preprocess, 41.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 40.1ms\n",
      "Speed: 0.0ms preprocess, 40.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 33.8ms\n",
      "Speed: 0.0ms preprocess, 33.8ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 33.4ms\n",
      "Speed: 0.0ms preprocess, 33.4ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 37.5ms\n",
      "Speed: 2.4ms preprocess, 37.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.6ms\n",
      "Speed: 0.0ms preprocess, 32.6ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.3ms\n",
      "Speed: 0.0ms preprocess, 24.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.5ms\n",
      "Speed: 0.6ms preprocess, 20.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.3ms\n",
      "Speed: 0.0ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 8.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.3ms\n",
      "Speed: 1.4ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 8.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.3ms\n",
      "Speed: 0.0ms preprocess, 23.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.3ms\n",
      "Speed: 0.0ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 24.3ms\n",
      "Speed: 0.0ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 22.2ms\n",
      "Speed: 2.8ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.9ms\n",
      "Speed: 0.0ms preprocess, 16.9ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 0.0ms preprocess, 17.3ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.5ms\n",
      "Speed: 3.9ms preprocess, 20.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 0.0ms preprocess, 13.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 19.2ms\n",
      "Speed: 0.0ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 18.4ms\n",
      "Speed: 2.3ms preprocess, 18.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.5ms\n",
      "Speed: 2.0ms preprocess, 14.5ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 3.1ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 1.6ms preprocess, 13.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.4ms\n",
      "Speed: 0.0ms preprocess, 16.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 3.1ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 2.5ms preprocess, 14.6ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.0ms\n",
      "Speed: 1.1ms preprocess, 16.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.5ms\n",
      "Speed: 5.0ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.8ms\n",
      "Speed: 0.8ms preprocess, 14.8ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 23.3ms\n",
      "Speed: 0.0ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.3ms\n",
      "Speed: 0.0ms preprocess, 16.3ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 0.0ms preprocess, 14.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.3ms\n",
      "Speed: 2.5ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 3.7ms preprocess, 13.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 1.2ms preprocess, 13.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.5ms\n",
      "Speed: 2.5ms preprocess, 13.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 2.9ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.6ms\n",
      "Speed: 3.2ms preprocess, 10.6ms inference, 9.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.7ms\n",
      "Speed: 0.0ms preprocess, 14.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 2.9ms preprocess, 14.3ms inference, 7.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.9ms\n",
      "Speed: 3.3ms preprocess, 17.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.7ms\n",
      "Speed: 4.6ms preprocess, 11.7ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 18.0ms\n",
      "Speed: 0.0ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 6.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 19.2ms\n",
      "Speed: 0.0ms preprocess, 19.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 0.0ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.8ms\n",
      "Speed: 0.0ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 1.2ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 0.0ms preprocess, 16.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.2ms\n",
      "Speed: 2.7ms preprocess, 14.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.8ms\n",
      "Speed: 0.0ms preprocess, 16.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.2ms\n",
      "Speed: 0.0ms preprocess, 15.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 1.9ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 2.4ms preprocess, 13.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "assert cap.isOpened()\n",
    "\n",
    "while True:\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    assert ret\n",
    "\n",
    "    results = predict(frame)\n",
    "    frame = plot_bboxes(results, frame)\n",
    "    \n",
    "    end_time = time()\n",
    "    fps = 1 / np.round(end_time - start_time, 2)\n",
    "\n",
    "    # cv2.putText(frame, f'FPS: {int(fps)}', (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)\n",
    "\n",
    "    # cv2.imshow('YOLOv8 Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0aa17-d287-4bc7-b8b9-14589c2fd35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "assert cap.isOpened()\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    assert ret\n",
    "\n",
    "    results = predict(frame)\n",
    "    # frame = plot_bboxes(results, frame)\n",
    "    \n",
    "    xyxys = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    # Extract detections for person class\n",
    "    for result in results[0]:\n",
    "        class_id = result.boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "        if class_id == 0:\n",
    "            xyxys.append(result.boxes.xyxy.cpu().numpy())\n",
    "            confidences.append(result.boxes.conf.cpu().numpy())\n",
    "            class_ids.append(result.boxes.cls.cpu().numpy().astype(int))\n",
    "\n",
    "    # Setup detections for visualization\n",
    "    detections = sv.Detections(\n",
    "        xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "        confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "        class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "    )\n",
    "\n",
    "    # Format custom labels\n",
    "    labels = [f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "                    for _, mask, confidence, class_id, tracker_id\n",
    "                    in detections]\n",
    "\n",
    "    # Annotate and display frame\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
    "\n",
    "    print()\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aef8ab-a29b-4f35-820a-5de9f0805594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
